{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"text-align: center;\">\n    <span style=\"font-weight: bold;\">Universidad de Buenos Aires</span>\n<br/>\n    Materia: <span style=\"font-weight: bold;\">Tecnologías emergentes</span><br/>\n<br/>\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/UBA.svg/1200px-UBA.svg.png\" width=\"150\"/>\n<br/>\n<br/>\n    Trabajo práctico sobre <span style=\"font-weight: bold;\">Machine Learning</span><br/>\n    Alumno: <span style=\"font-weight: bold;\">Mariano La Penna</span><br/>\nPadrón 98.432<br/>\n<br/>\nDiciembre de 2022<br/>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-weight: bold;\">Descripción e intención</span><br/><br/>\nEl presente trabajo práctico, de carácter individual, consiste en haber replicado un notebook público que resuelve una competencia de Kaggle de detección de tejidos linfáticos tumorales, e intercalarle de principio a fin explicaciones en español de las sentencias de código. Dicha tarea implicó el aprendizaje de un montón de asuntos: librerías, métodos, atributos, sintaxis, etc. y explicarlos en un lenguaje entre \"técnico\" y \"criollo\" :)<br/><br/>\nEl propósito no es solo cumplir con la práctica de un contenido de la materia, sino, de poner luego en dominio público un notebook de un asunto bastante complejo, listo para ser leído por principiantes, aspirando a que puedan lograr su total comprensión, ya que más de una vez me he encontrado tratando de entender código ajeno, o incluso replicándolo yo, sin saber la mayoría de las líneas qué función cumplían, y se demora bastante tiempo en abrir otra ventana de navegador, y buscar documentación, línea por línea, que como casi siempre es en inglés y en este caso con más proporción de palabras técnicas que no siempre son comunes.<br/>De esta forma se provee una forma más cómoda para su estudio.<br/>\n<br/>\nCompetencia original: https://www.kaggle.com/c/histopathologic-cancer-detection<br/>\nNotebook original: https://www.kaggle.com/code/leeking/cnn-conv2d-separableconv2d-keras-new-model-1","metadata":{}},{"cell_type":"code","source":"# Este entorno de Python 3 viene con varias librerías analíticas útiles instaladas\n# Está definido por la imagen docker de kaggle/python: https://github.com/kaggle/docker-python\n# Por ejemplo, tiene varios paquetes útiles para cargar.\n# Los archivos de entrada están disponibles en la carpeta \"../input/\" o \"/kaggle/input\"\n\n# Biblioteca de algebra lineal: vectores, matrices, funciones matemáticas de alto nivel...\nimport numpy as np \n\n # Librería de procesamiento de datos, se usa por ejemplo para leer los archivos CSV I/O (ej: pd.read_csv)\nimport pandas as pd\n\n# Permite ejecutar ciertos comandos aquí en el notebook, como si fueran ejecutados en una consola (shell)\nimport os \n \n# El módulo GLOB se usa para buscar rutas de archivos, de acuerdo a un patrón que sigue las reglas de la \n# consola (shell) de Unix\nfrom glob import glob\n\n# SHUFFLE (en inglés \"barajar\"), recibe una secuencia de items (como una lista) y reorganiza el orden.\nfrom random import shuffle \n \n# OpenCV -> \"OPEN Computer Vision\", librería que se ocupa de \"problemas\" de reconocimiento de imágenes\nimport cv2\n\n# PYPLOT viene de PYthon PLOT (plot = gráfico). pyplot es una interfaz basada en estados para MATPLOTLIB.\n# Y MATPLOTLIB es una librería para generar gráficos en 2D. Son los que se usan al final de este notebook.\nimport matplotlib.pyplot as plt\n    \n\n# SKLEARN (Scikit-learn) es una librería de aprendizaje automático que provee versiones eficaces de algoritmos \n# comunes.\n# MODEL_SELECTION es un método para establecer un \"blueprint\" (plano, diseño) para analizar datos y luego\n# usarlo para medir nuevos datos. Construir un modelo adecuado mejora las predicciones.\n# TRAIN_TEST_SPLIT (como su nombre lo declara)  sirve para dividir un dataset en dos: training y test. Este\n# último se usa para evaluar la performance del modelo.\nfrom sklearn.model_selection import train_test_split\n\n# KERAS: biblioteca de redes neuronales\n# PREPROCESSING: sirve para, partiendo de datos crudos almacenados en disco (hoy disco ya no es literal), a un\n# dataset útil para entrenar un modelo.\n# IMAGE: el preprocesamiento, específicamente para imágenes\n# IMAGEDATAGENERATOR: genera lotes de datos de imágenes con aumento de datos (data augmentation) en tiempo real, \n# o sea en el momento.\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# LAYERS (capas) son los bloques de construcción de redes neuronales en Keras. Se usarán para construir las \n# capas del modelo, a través de las cuáles el software interpretará las imágenes (con los parámetros -weights-\n# que irá descubriendo).\n# INPUT se usa para definir la entrada de datos al modelo: la estructura (shape) de los datos de cada imagen \n# (96,96,3).\nfrom keras import layers, Input\n\n# LOSSES (pérdidas) son un conjunto de funciones cuyo propósito es definir cómo se computa la \"cantidad\"\n# (o monto) que el modelo debe buscar minimizar durante el entrenamiento.\n# MAE (mean absolute error) calcula el promedio de la diferencia absoluta (o sea en módulo) entre las \n# predicciones y los labels reales.\n# SPARSE_CATEGORICAL_CROSSENTROPY calcula la entropía cruzada que es un valor probabilístico calculado sumatoria\n# y logaritmos.\n# BINARY_CROSSENTROPY (entropía cruzada binaria) un cálculo similar al anterior, pero solo para labels binarios,\n# como este.\nfrom keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n\n# keras.MODELS ofrece varias formas de crear modelos, que son el compilado de capas (layers) definidos aquí en \n# el notebook...\n# MODEL es uno de estos modelos posibles a crear, que agrupa un conjunto (no necesariamente lineal / secuencial) \n# de capas creando un solo objeto con ellas.\nfrom keras.models import Model\n\n# keras.APPLICATIONS son modelos de aprendizaje profundo que se proveen (eventualmente) con parámetros (weights)\n# pre entrenados.\n# NASNET (Neural Architecture Search NETwork) es una arquitectura, una familia de modelos que fueron creados\n# para datasets específicos, ya incluyen las capas (layers) de un modelo, de acuerdo a ciertos parámetros. Posee\n# dos tipos de capas: normal y de reducción.\n# PREPROCESS_INPUT realiza un preprocesamiento de un tensor o matriz Numpy que tienen codificado un lote de \n# imágenes, así adecua la imagen al formato que el modelo necesita.\n# https://www.tensorflow.org/api_docs/python/tf/keras/applications/nasnet/preprocess_input\nfrom keras.applications.nasnet import preprocess_input\n\n# Corregido respecto al notebook original que los importaba de keras.optimizers\n# Un OPTIMIZER (optimizador) se usa para mejorar la velocidad y performance para entrenar un modelo específico.\n# ADAM (Adaptive Moment Estimation) agrega dos variables adicionales para cada variable a entrenar. El propósito\n# es calcular las tasas de aprendizaje adaptativo para cada parámetro: diferentes partes de la red neuronal\n# tienen diferente sensibilidad al ajuste de peso (weights).\n# RMSprop: cada parámetro puede tener diferente tasa de aprendizaje, es como AdaGrad pero se agrega un \n# coeficiente de atenuación. RMSprop se basa en Rprop.\nfrom tensorflow.keras.optimizers import Adam, RMSprop \n\n# CALLBACKS, tal como su nombre lo indica son llamadas a determinadas acciones en algún momento del entrenamiento,\n# por ejemplo al inicio o fin de una \"epoch\", o luego de un lote (batch). Se pueden usar por ejemplo para loguear,\n# guardar el modelo o detener antes de tiempo.\n# MODELCHECKPOINT es un callback para grabar el modelo o sus pesos cada cierta frecuencia. Se define qué grabar,\n# la frecuencia, etc.\n# EARLYSTOPPING como su nombre lo sugiere, produce una interrupción temprana del entrenamiento cuando por ejemplo\n# la pérdida (loss) ya no está disminuyendo (considerando, si aplica, min_delta y patience -número de epochs de \n# tolerancia-).\n# REDUCE LR ON PLATEAU reduce la tasa de aprendizaje cuando un modelo, durante el entrenamiento, deja de mejorar.\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# IMGAUG es una librería para \"data augmentation\" en imágenes. El aumento de imágenes consiste en generar más \n# variantes de las mismas imágenes, aumentando así el dataset de entrenamiento. Se hacen variaciones, rotaciones,\n# se quitan de foco, cambian algunos colores, etc., manteniendo el mismo label.\n# Más info: https://albumentations.ai/docs/introduction/image_augmentation/\nfrom imgaug import augmenters as iaa\n\n# Librería de aumento de imágenes\nimport imgaug as ia\n\n# Lee la carpeta \"../input\" relativa a la carpeta actual e imprime su contenido en pantalla.\nprint(os.listdir(\"../input\"))\n\n# leo planilla de entrenamiento\ndf_train = pd.read_csv(\"../input/histopathologic-cancer-detection/train_labels.csv\")\n\n# Cualquier resultado grabado en el directorio actual se graba en '/output'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-12T00:18:09.680912Z","iopub.execute_input":"2022-12-12T00:18:09.681589Z","iopub.status.idle":"2022-12-12T00:18:10.639373Z","shell.execute_reply.started":"2022-12-12T00:18:09.681537Z","shell.execute_reply":"2022-12-12T00:18:10.637843Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['histopathologic-cancer-detection']\n","output_type":"stream"}]},{"cell_type":"code","source":"# La función ZIP devuelve justamente un objeto ZIP que nada tiene que ver con compresión de datos, sino que es un \n# iterador de tuplas, donde los elementos (en este caso) df_train.id y df_train.label se van devolviendo a pares.\n# Lo de K:V FOR K,V genera un \"diccionario\" con todos esos pares, como una lista tipo clave-valor.\nid_label_map = {k:v for k,v in zip(df_train.id.values, df_train.label.values)}\n\n# El conocido HEAD() devuelve los 5 primeros items del dataframe, no se para qué explico esto! :)\ndf_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-12T00:18:18.931849Z","iopub.execute_input":"2022-12-12T00:18:18.932537Z","iopub.status.idle":"2022-12-12T00:18:19.067370Z","shell.execute_reply.started":"2022-12-12T00:18:18.932482Z","shell.execute_reply":"2022-12-12T00:18:19.065945Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                         id  label\n0  f38a6374c348f90b587e046aac6079959adf3835      0\n1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n2  755db6279dae599ebb4d39a9123cce439965282d      0\n3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n4  068aba587a4950175d04c680d38943fd488d6a9d      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Función que como su nombre dice, devuelve el id (de imagen), partiendo de la ruta y nombre de uno de los \n# archivos. OS.PATH.SEP es el \"SEParador para este sistema operativo (OS) de rutas (PATH). Toma el final (-1) de\n# los elementos separados (SPLIT) de la ruta y le quita el \".tif\" con la función REPLACE. Como los ids archivos\n# son una cadena alfanumérica de 40 caracteres con extensión tif, devuelve solo esos 40 caracteres, que son el \n# id.\ndef get_id_from_file_path(file_path):\n    return file_path.split(os.path.sep)[-1].replace('.tif', '')","metadata":{"execution":{"iopub.status.busy":"2022-12-12T00:18:24.064297Z","iopub.execute_input":"2022-12-12T00:18:24.064699Z","iopub.status.idle":"2022-12-12T00:18:24.070830Z","shell.execute_reply.started":"2022-12-12T00:18:24.064668Z","shell.execute_reply":"2022-12-12T00:18:24.069630Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Esto demora un poquito... carga los nombres de los archivos existentes \"en disco\", en las variables.\nlabeled_files = glob('../input/histopathologic-cancer-detection/train/*.tif')\ntest_files = glob('../input/histopathologic-cancer-detection/test/*.tif')\n\n# Se muestra en pantalla los totales de archivos leídos.\nprint(\"labeled_files size :\", len(labeled_files))\nprint(\"test_files size :\", len(test_files))","metadata":{"execution":{"iopub.status.busy":"2022-12-12T00:18:26.246145Z","iopub.execute_input":"2022-12-12T00:18:26.246573Z","iopub.status.idle":"2022-12-12T00:18:50.967139Z","shell.execute_reply.started":"2022-12-12T00:18:26.246527Z","shell.execute_reply":"2022-12-12T00:18:50.965890Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"labeled_files size : 220025\ntest_files size : 57458\n","output_type":"stream"}]},{"cell_type":"code","source":"# Se divide el set de entrenamiento en dos subconjuntos: entrenamiento y validacion. El RANDOM_STATE es una forma\n# de efectuar una selección al azar, pero que será siempre la misma cada vez que se ejecute. ¿Se entiende?\ntrain, val = train_test_split(labeled_files, test_size=0.1, random_state=101010)","metadata":{"execution":{"iopub.status.busy":"2022-12-12T00:19:04.092663Z","iopub.execute_input":"2022-12-12T00:19:04.093087Z","iopub.status.idle":"2022-12-12T00:19:04.179825Z","shell.execute_reply.started":"2022-12-12T00:19:04.093051Z","shell.execute_reply":"2022-12-12T00:19:04.178610Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# CHUNKER lo que hace es recibir un dataframe y recortarlo en porciones de tamaño SIZE, devolviendo tuplas en \n# las que cada una contiene una de esas esas \"porciones\".\n# RANGE(0, len(seq), size) crea una secuencia de números desde 0, hasta la cantidad de elementos en SEQ (menos \n# uno), pero los incrementos son de SIZE. Ejemplo: 0, 3, 6, 9 ...\n# SEC[pos:pos + size] corta una secuencia arrancando desde uno de los números devueltos por RANGE, de largo SIZE.\ndef chunker(seq, size):\n    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n\n\n# Esta función genera (y retorna) una secuencia de aumentadores (data augmentation) para aplicarle a imágenes.\ndef get_seq():\n    \n    # Se define la variable SOMETIMES que luego se usa en forma de función para que no todos los \n    # aumentadores se apliquen, de esa forma se logra una variedad en las transformaciones y se suaviza el\n    # efecto (comparado con que se apliquen todas juntas a una misma imagen) así la imagen no se deforma\n    # tanto que ya no sirva.\n    # https://imgaug.readthedocs.io/en/latest/source/examples_basics.html#heavy-augmentations\n    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n    \n    # Se define una secuencia de aumentadores\n    seq = iaa.Sequential(\n        [\n            # https://imgaug.readthedocs.io/en/latest/source/api_augmenters_flip.html\n            iaa.Fliplr(0.5), # Invertir horizontalmente el 50% de todas las imágenes\n            iaa.Flipud(0.2), # Invertir verticalmente el 50% de todas las imágenes\n            \n            # Guía en: https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html\n            sometimes(iaa.Affine(\n                # Cambiar tamaño de imágenes a 80-120% de su tamaño, individualmente, por eje\n                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, \n                \n                # Mover entre -20 y +20 % las imágenes independiéntemente, por eje\n                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, \n                \n                rotate=(-10, 10), # Rotar entre -45 y +45 grados\n                \n                # Torcer (es como rotar pero dejando la base y tope horizontales) entre -16 y +16 grados\n                shear=(-5, 5), \n                \n                order=[0, 1], # Usar \"nearest neighbour\" o \"bilinear interpolation\" para el resampleado (rápido)\n                cval=(0, 255), # Si el modo es constante, usar un cval entre 0 y 255 (equivalente a ALL)\n                mode=ia.ALL # Usar alguno de los modos de deformación de imágenes de scikit\n            )),\n            \n            # Ejecutar entre 0 y 5 de los siguientes (menos importantes) aumentadores (augmenters) por imagen.\n            # No ejecutar todos, porque eso habitualmente sería muy fuerte.\n            iaa.SomeOf((0, 5),\n                [\n                    # Convertir imágenes a su representación en superpíxeles\n                    # ¿Qué son los superpíxeles? \n                    # https://www.tu-chemnitz.de/etit/proaut/en/research/superpixel.html\n                    sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))),                     \n                    \n                    # ONEOF ejecuta azarósamente solo uno (cada vez) de los métodos listados dentro.\n                    # https://imgaug.readthedocs.io/en/latest/source/overview/meta.html#oneof\n                    iaa.OneOf([\n                        # Guía para los 3 en https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blur.html\n                        \n                        # Borronear imágenes con un sigma entre 0 y 3.0\n                        iaa.GaussianBlur((0, 1.0)),\n                        \n                        # Borronear imagen usando promedios locales con tamaños de kernel entre 2 y 7\n                        iaa.AverageBlur(k=(3, 5)), \n                        \n                        # Borronear imagen usando medianas locales con tamaños de kernel entre 2 y 7\n                        iaa.MedianBlur(k=(3, 5)), \n                    ]),\n                    \n                    # Mejorar nitidez de imagen\n                    # https://imgaug.readthedocs.io/en/latest/source/overview/convolutional.html#sharpen\n                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), \n                    \n                    # Mejorar nitidez de imagen\n                    # https://imgaug.readthedocs.io/en/latest/source/overview/convolutional.html#emboss\n                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # Estampar imagen\n                    \n                    # Buscar todos los bordes o bien los bordes dirigidos,\n                    # mezclar el resultado con la imagen original usando una máscara de manchas.\n                    # Explicación del mezclado: https://imgaug.readthedocs.io/en/latest/source/alpha.html\n                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n                        # Resalta los bordes\n                        # https://imgaug.readthedocs.io/en/latest/source/overview/convolutional.html#edgedetect                        \n                        iaa.EdgeDetect(alpha=(0.5, 1.0)),\n                        \n                        # Resalta bordes con una dirección determinada\n                        # https://imgaug.readthedocs.io/en/latest/source/overview/convolutional.html#directededgedetect\n                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n                    ])),\n                    \n                    # Agregar \"ruido\" de acuerdo a una distribución gaussiana\n                    # https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#additivegaussiannoise\n                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5),\n                    \n                    iaa.OneOf([\n                        # Azarosamente remueve hasta el 10% de los pixeles (pasan a ser píxeles negros)\n                        # https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#additivegaussiannoise\n                        iaa.Dropout((0.01, 0.05), per_channel=0.5), \n                        \n                        # Similar al dropout de arriba pero en lugar de píxeles aislados, lo hace en \n                        # varios grupos que forman pequeños rectángulos.\n                        # https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#coarsedropout\n                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n                    ]),\n                    \n                    # Invierte canales de color de acuerdo a parámetros. \n                    # https://imgaug.readthedocs.io/en/latest/source/overview/arithmetic.html#invert\n                    iaa.Invert(0.01, per_channel=True),\n                    \n                    # Cambia el brillo (agrega valores a los píxeles), entre -2 y 2\n                    # https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Add\n                    iaa.Add((-2, 2), per_channel=0.5), \n                    \n                    # Decrementa o incrementa tonalidad y saturación.\n                    # https://imgaug.readthedocs.io/en/latest/source/overview/color.html#addtohueandsaturation\n                    iaa.AddToHueAndSaturation((-1, 1)), \n                    \n                    iaa.OneOf([\n                        # Multiplica todos los píxels de la imagen, por un valor aleatorio dentro del rango\n                        # parametrizado, el mismo valor para toda la imagen\n                        # https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Multiply\n                        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n                        \n                        # Alpha se refiere a la transparencia de una porción de una imagen (desde un píxel a toda\n                        # la imagen). Este aumentador toma una imagen, le hace un efecto como el de bordes en \n                        # sobrerelieve (en toda una imagen en blanco/negro) y luego la fusiona con la imagen \n                        # original (blend) en modo alpha (trasparencias, no aditivo) usando una máscara de ruido\n                        # de frecuencia.\n                        # https://imgaug.readthedocs.io/en/latest/source/alpha.html#frequencynoisealpha\n                        iaa.FrequencyNoiseAlpha(\n                            exponent=(-1, 0),\n                            first=iaa.Multiply((0.9, 1.1), per_channel=True),\n                            second=iaa.ContrastNormalization((0.9, 1.1))\n                        )\n                    ]),\n                    \n                    # Como su nombre sugiere \"elastic\", mueve pixels localmente alrededor de su posición original, \n                    # con fuerzas aleatorias.\n                    # https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#elastictransformation\n                    sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), \n                    \n                    # Piecewise: por partes, afine: que conserva mayormente la dirección de las lineas pero\n                    # puede alternar su distancia y ángulos.\n                    # Genera distorciones locales que se ven como áreas \"torcidas\" en la imagen.\n                    # https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#piecewiseaffine\n                    sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n                    \n                    # \"Transforma la perspectiva\": coloca 4 puntos, uno cerca de cada esquina de la imagen, a\n                    # distancias aleatorias dentro de un rango, formando así un polígono, luego recorta la imagen\n                    # por los bordes del polígono y mueve esos nuevos bordes para volver a formar un cuadrado. \n                    # https://imgaug.readthedocs.io/en/latest/source/overview/geometric.html#perspectivetransform\n                    sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n                ],\n                random_order=True # Los aumentadores se ejecutan en orden aleatorio\n            )\n        ],\n        random_order=True # Los aumentadores (en grupos o individuales) se ejecutan en orden aleatorio\n    )\n    return seq\n\n\n# Función que devuelve las imágenes originales ya leídas de disco más todas sus variantes aumentadas (si asi se pidió\n# por parámetro) ya preprocesadas, junto con el label de cada una, para iterar todas una vez.\n# list_files: los archivos encontrados en \"disco\"\n# id_label_map: el iterador de tuplas, del dataset de entrenamiento (id -> label)\n# batch_size: tamaño del lote\n# augment: si se aplican o no los aumentadores de imágenes\ndef data_gen(list_files, id_label_map, batch_size, augment = False):\n    seq = get_seq() # La secuencia de aumentadores\n    while True:\n        shuffle(list_files) # Mezclar el listado\n        for batch in chunker(list_files, batch_size): # Por cada lote, cortado del tamaño batch_size\n            X = [cv2.imread(x) for x in batch] # Se lee cada imagen desde \"disco\"\n            Y = [id_label_map[get_id_from_file_path(x)] for x in batch] # Se lee el label\n            if augment:\n                X = seq.augment_images(X) # Se generan las variantes adicionales de las imágenes\n            X = [preprocess_input(x) for x in X] # Se preprocesan las imágenes originales y sus variantes\n                \n            yield np.array(X), np.array(Y) # Devuelve un generador de la lista de imagenes, para iterar una vez.\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-16T16:06:01.936236Z","iopub.execute_input":"2022-12-16T16:06:01.937309Z","iopub.status.idle":"2022-12-16T16:06:01.965130Z","shell.execute_reply.started":"2022-12-16T16:06:01.937266Z","shell.execute_reply":"2022-12-16T16:06:01.963818Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def get_model_classif_nasnet():  \n    # epoch = 20 ---- 95.87%\n    inputs = Input((96, 96, 3)) # Ya explicado en el primer bloque de código\n\n    # Las redes convolucionales, basadas en la biología de la visión, toman grupos de píxeles cercanos y van\n    # operando, calculando datos y pasándoselos de capa en capa para obtener así patrones / conclusiones sobre\n    # la imagen.\n    # Arranca con un filtro convolucional en 2 dimensiones, es una capa del modelo, según los parámetros esta \n    # tendrá 32 filtros y un \"stride\" (paso) de 3 píxeles, o sea que se va moviendo de a 3 píxeles cada vez que\n    # va recorriendo la imagen de entrada. Producirá 32 matrices de salida. El padding -> 'same' significa que\n    # el tamaño de las matrices de salida no se reducirán por aplicar padding alguno.\n    # https://keras.io/api/layers/convolution_layers/convolution2d/\n    x1 = layers.Conv2D(32, 3, padding='same')(inputs) \n    \n    # Se normaliza la capa anterior, normalización de lote es transformar los valores obtenidos para que \n    # promedien 0, y que la desviación estandar sea 1. La variable 'x1' es la entrada de esta capa, que a su \n    # vez se sobreescribe con la salida.\n    # https://keras.io/api/layers/normalization_layers/batch_normalization/\n    x1 = layers.BatchNormalization()(x1)\n    \n    # Se aplica la función de activación RELU a la salida de la capa previa.\n    # Una función de activación recibe varias entradas y devuelve una salida transformando la combinación de \n    # entradas, pesos y sesgos para la siguiente capa del modelo. \n    # Se pueden usar varias funciones, en este caso se usa RELU -> REctified Linear activation Unit. En \n    # español: Función Lineal de Activación Rectificada.\n    # https://keras.io/api/layers/activations/\n    x1 = layers.Activation('relu')(x1)\n    \n    # Otra capa convolucional\n    x1 = layers.Conv2D(32,3,padding='same')(x1)\n    \n    x1 = layers.BatchNormalization()(x1)\n    x1 = layers.Activation('relu')(x1)\n    x1 = layers.Conv2D(32,3,padding='same')(x1)\n    x1 = layers.BatchNormalization()(x1)\n    x1 = layers.Activation('relu')(x1)\n    \n    # Max-Pooling, para secciones de la imagen se obtiene la feature más importante. Es otra manera de obtener\n    # información local, aparte de la capa convolucional. En este caso el tamaño de salida es 2x2 y la entrada\n    # es la capa previa, de mayor tamaño.\n    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n    x1 = layers.MaxPool2D(2,2)(x1)  \n\n    # Se siguen aplicando capas ya explicadas\n    x2 = layers.Conv2D(64,3,padding='same')(x1)\n    x2 = layers.BatchNormalization()(x2)\n    x2 = layers.Activation('relu')(x2)\n    x2 = layers.Conv2D(64,3,padding='same')(x2)\n    x2 = layers.BatchNormalization()(x2)\n    x2 = layers.Activation('relu')(x2)\n    x2 = layers.Conv2D(64,3,padding='same')(x2)\n    x2 = layers.BatchNormalization()(x2)\n    x2 = layers.Activation('relu')(x2)\n    residual_x1 = layers.Conv2D(64,1,strides=1,padding='same')(x1)\n    \n    # Suma dos capas y devuelve una.\n    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add\n    x2 = layers.add([x2,residual_x1])\n    \n    x2 = layers.MaxPool2D(2,2)(x2)\n    \n    # Una convolución que se realiza de manera independiente por cada uno de los canales (en este caso 3) de\n    # la entrada, y cada matriz resultante se forma juntando los 3 canales resultantes.\n    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv2D\n    # https://paperswithcode.com/method/depthwise-convolution\n    x2_s = layers.SeparableConv2D(64,3,padding='same')(x2)\n    \n    x2_s = layers.BatchNormalization()(x2_s)\n    x2_s = layers.Activation('relu')(x2_s)\n    x2_s = layers.SeparableConv2D(64,3,padding='same')(x2_s)\n    x2_s= layers.BatchNormalization()(x2_s)\n    x2_s= layers.Activation('relu')(x2_s)\n    x2_s = layers.SeparableConv2D(64,3,padding='same')(x2_s)\n    x2_s= layers.BatchNormalization()(x2_s)\n    x2_s= layers.Activation('relu')(x2_s)\n    x2_s = layers.add([x2_s,x2]) \n    x2_s = layers.MaxPool2D(2,2)(x2_s)\n    \n    x3 = layers.Conv2D(128,3,padding='same')(x2)\n    x3 = layers.BatchNormalization()(x3)\n    x3 = layers.Activation('relu')(x3)\n    x3 = layers.Conv2D(128,3,padding='same')(x3)\n    x3 = layers.BatchNormalization()(x3)\n    x3 = layers.Activation('relu')(x3)\n    x3 = layers.Conv2D(128,3,padding='same')(x3)\n    x3 = layers.BatchNormalization()(x3)\n    x3 = layers.Activation('relu')(x3)\n    residual_x2 = layers.Conv2D(128,1,strides=1,padding='same')(x2)\n    x3 = layers.add([residual_x2,x3]) \n    \n    x3_x3 = layers.Conv2D(128,3,padding='same')(x3)\n    x3_x3 = layers.BatchNormalization()(x3_x3)\n    x3_x3 = layers.Activation('relu')(x3_x3)\n    x3_x3 = layers.Conv2D(128,3,padding='same')(x3_x3)\n    x3_x3 = layers.BatchNormalization()(x3_x3)\n    x3_x3 = layers.Activation('relu')(x3_x3)\n    x3_x3 = layers.Conv2D(128,3,padding='same')(x3_x3)\n    x3_x3 = layers.BatchNormalization()(x3_x3)\n    x3_x3 = layers.Activation('relu')(x3_x3)\n    x3_x3 = layers.add([x3,x3_x3]) \n    x3_x3 = layers.MaxPool2D(2,2)(x3_x3)\n    \n    # Concatena las matrices de entrada.\n    # https://keras.io/api/layers/merging_layers/concatenate/\n    concetenated_1 = layers.concatenate([x3_x3,x2_s])\n    \n    x3_s = layers.SeparableConv2D(128,3,padding='same')(concetenated_1)\n    x3_s = layers.BatchNormalization()(x3_s)\n    x3_s = layers.Activation('relu')(x3_s)\n    x3_s = layers.SeparableConv2D(128,3,padding='same')(x3_s)\n    x3_s= layers.BatchNormalization()(x3_s)\n    x3_s= layers.Activation('relu')(x3_s)\n    x3_s = layers.SeparableConv2D(128,3,padding='same')(x3_s)\n    x3_s= layers.BatchNormalization()(x3_s)\n    x3_s= layers.Activation('relu')(x3_s)\n    x3_s = layers.add([x3_s,x3_x3]) \n    x3_s = layers.MaxPool2D(2,2)(x3_s)\n    \n    x4 = layers.Conv2D(256,3,padding='same')(x3_x3)\n    x4 = layers.BatchNormalization()(x4)\n    x4 = layers.Activation('relu')(x4)\n    x4 = layers.Conv2D(256,3,padding='same')(x4)\n    x4 = layers.BatchNormalization()(x4)\n    x4 = layers.Activation('relu')(x4)\n    x4 = layers.Conv2D(256,3,padding='same')(x4)\n    x4 = layers.BatchNormalization()(x4)\n    x4 = layers.Activation('relu')(x4)\n    residual_x3 = layers.Conv2D(256,1,strides=1,padding='same')(x3_x3)\n    x4 = layers.add([residual_x3,x4]) \n    \n    x4_x4 = layers.Conv2D(256,3,padding='same')(x4)\n    x4_x4 = layers.BatchNormalization()(x4_x4)\n    x4_x4 = layers.Activation('relu')(x4_x4)\n    x4_x4 = layers.Conv2D(256,3,padding='same')(x4_x4)\n    x4_x4 = layers.BatchNormalization()(x4_x4)\n    x4_x4 = layers.Activation('relu')(x4_x4)\n    x4_x4 = layers.Conv2D(256,3,padding='same')(x4_x4)\n    x4_x4 = layers.BatchNormalization()(x4_x4)\n    x4_x4 = layers.Activation('relu')(x4_x4)\n    x4_x4 = layers.add([x4,x4_x4]) \n    x4_x4 = layers.MaxPool2D(2,2)(x4_x4)\n\n    concetenated_2 = layers.concatenate([x4_x4,x3_s])\n    x4_s = layers.SeparableConv2D(256,3,padding='same')(concetenated_2)\n    x4_s = layers.BatchNormalization()(x4_s)\n    x4_s = layers.Activation('relu')(x4_s)\n    x4_s = layers.SeparableConv2D(256,3,padding='same')(x4_s)\n    x4_s= layers.BatchNormalization()(x4_s)\n    x4_s= layers.Activation('relu')(x4_s)\n    x4_s = layers.SeparableConv2D(256,3,padding='same')(x4_s)\n    x4_s= layers.BatchNormalization()(x4_s)\n    x4_s= layers.Activation('relu')(x4_s)\n    x4_s = layers.add([x4_s,x4_x4]) \n    x4_s = layers.MaxPool2D(2,2)(x4_s)\n    \n    x5 = layers.Conv2D(512,3,padding='same')(x4_x4)\n    x5 = layers.BatchNormalization()(x5)\n    x5 = layers.Activation('relu')(x5)\n    x5 = layers.Conv2D(512,3,padding='same')(x5)\n    x5 = layers.BatchNormalization()(x5)\n    x5 = layers.Activation('relu')(x5)\n    x5 = layers.Conv2D(512,3,padding='same')(x5)\n    x5 = layers.BatchNormalization()(x5)\n    x5 = layers.Activation('relu')(x5)\n    residual_x4 = layers.Conv2D(512,1,strides=1,padding='same')(x4_x4)\n    x5 = layers.add([residual_x4,x5])\n\n    x5_x5 = layers.Conv2D(512,3,padding='same')(x5)\n    x5_x5 = layers.BatchNormalization()(x5_x5)\n    x5_x5 = layers.Activation('relu')(x5_x5)\n    x5_x5 = layers.Conv2D(512,3,padding='same')(x5_x5)\n    x5_x5 = layers.BatchNormalization()(x5_x5)\n    x5_x5 = layers.Activation('relu')(x5_x5)\n    x5_x5 = layers.Conv2D(512,3,padding='same')(x5_x5)\n    x5_x5 = layers.BatchNormalization()(x5_x5)\n    x5_x5 = layers.Activation('relu')(x5_x5)\n    x5_x5 = layers.add([x5,x5_x5])\n    x5_x5 = layers.MaxPool2D(2,2)(x5_x5)\n    \n    concetenated_3 = layers.concatenate([x5_x5,x4_s])\n    x5_s = layers.SeparableConv2D(512,3,padding='same')(concetenated_3)\n    x5_s = layers.BatchNormalization()(x5_s)\n    x5_s = layers.Activation('relu')(x5_s)\n    x5_s = layers.SeparableConv2D(512,3,padding='same')(x5_s)\n    x5_s= layers.BatchNormalization()(x5_s)\n    x5_s= layers.Activation('relu')(x5_s)\n    x5_s = layers.SeparableConv2D(512,3,padding='same')(x5_s)\n    x5_s= layers.BatchNormalization()(x5_s)\n    x5_s= layers.Activation('relu')(x5_s)\n    x5_s = layers.add([x5_s,x5_x5]) \n\n    # Global Average (promedio) Pooling calcula la salida promedio de cada mapa de características de la capa\n    # previa. Esta simple operación reduce significativamente los datos y prepara el modelo para la capa de\n    # clasificación final. No tiene parámetros entrenables.\n    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D\n    # https://adventuresinmachinelearning.com/global-average-pooling-convolutional-neural-networks/\n    x = layers.GlobalAveragePooling2D()(x5_s)\n\n    # Capa usada en las etapas finales de la red neuronal, que cambia la dimensionalidad de la salida para que\n    # el modelo pueda definir la relación entre las características detectadas y los labels. 64 es la dimensión\n    # del vector de salida.\n    # https://keras.io/api/layers/core_layers/dense/\n    # https://analyticsindiamag.com/a-complete-understanding-of-dense-layers-in-neural-networks/\n    x = layers.Dense(64)(x)\n    \n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    \n    # El 20% de las neuronas (ya que el parámetro es 0.2) elegidas aleatoramente se ignoran, y el otro 80% se\n    # divide por 0.8 (o sea se incrementa) para que el promedio no se altere. El propósito de ignorar una\n    # porción es evitar que el modelo haga overfitting (sobreajuste).\n    # https://keras.io/api/layers/regularization_layers/dropout/\n    # https://www.aprendemachinelearning.com/que-es-overfitting-y-underfitting-y-como-solucionarlo/\n    x = layers.Dropout(0.2)(x)\n    \n    # La función sigmoide es otra posible función de activación.\n    # https://es.wikipedia.org/wiki/Funci%C3%B3n_sigmoide\n    # El objetivo es por ejemplo definir si un 0,7 es un SI o un NO, lo mismo con cualquier valor como 0,1...\n    # 0,8... etc. Para obtener así la predicción booleana de si la imágen es tumoral o no.\n    output_tensor = layers.Dense(1, activation='sigmoid')(x)\n\n    # Aquí se le crea el objeto de modelo con las capas definidas\n    model = Model(inputs,output_tensor)\n    \n    # Configura el modelo para el entrenamiento. Se define el optimizador, la función de pérdida y las métricas\n    # (acc) a evaluar durante entrenamiento y testing\n    # https://keras.io/api/models/model_training_apis/\n    model.compile(optimizer=Adam(0.01), loss=binary_crossentropy, metrics=['acc'])\n    \n    # Muestra en pantalla la estructura terminada del modelo, con sus capas, parámetros, etc.\n    model.summary()\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-12-12T00:19:13.001354Z","iopub.execute_input":"2022-12-12T00:19:13.001819Z","iopub.status.idle":"2022-12-12T00:19:13.069196Z","shell.execute_reply.started":"2022-12-12T00:19:13.001780Z","shell.execute_reply":"2022-12-12T00:19:13.067610Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = get_model_classif_nasnet()","metadata":{"execution":{"iopub.status.busy":"2022-12-12T00:19:20.818922Z","iopub.execute_input":"2022-12-12T00:19:20.819751Z","iopub.status.idle":"2022-12-12T00:19:22.088274Z","shell.execute_reply.started":"2022-12-12T00:19:20.819702Z","shell.execute_reply":"2022-12-12T00:19:22.087318Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-12-12 00:19:20.881805: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 96, 96, 32)   896         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 96, 96, 32)   128         conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 96, 96, 32)   0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 96, 96, 32)   9248        activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 96, 96, 32)   128         conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 96, 96, 32)   0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 96, 96, 32)   9248        activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 96, 96, 32)   128         conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 96, 96, 32)   0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 48, 48, 32)   0           activation_2[0][0]               \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 48, 48, 64)   18496       max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 48, 48, 64)   256         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 48, 48, 64)   0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 48, 48, 64)   36928       activation_3[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 48, 48, 64)   256         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 48, 48, 64)   0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 48, 48, 64)   36928       activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 48, 48, 64)   256         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 48, 48, 64)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 48, 48, 64)   2112        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nadd (Add)                       (None, 48, 48, 64)   0           activation_5[0][0]               \n                                                                 conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 24, 24, 64)   0           add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 24, 24, 128)  73856       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 24, 24, 128)  512         conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 24, 24, 128)  0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 24, 24, 128)  147584      activation_9[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 24, 24, 128)  512         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 24, 24, 128)  0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 24, 24, 128)  147584      activation_10[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 24, 24, 128)  512         conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 24, 24, 128)  8320        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 24, 24, 128)  0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 24, 24, 128)  0           conv2d_10[0][0]                  \n                                                                 activation_11[0][0]              \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 24, 24, 128)  147584      add_2[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 24, 24, 128)  512         conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 24, 24, 128)  0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 24, 24, 128)  147584      activation_12[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 24, 24, 128)  512         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 24, 24, 128)  0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 24, 24, 128)  147584      activation_13[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 24, 24, 128)  512         conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 24, 24, 128)  0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 24, 24, 128)  0           add_2[0][0]                      \n                                                                 activation_14[0][0]              \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 128)  0           add_3[0][0]                      \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 12, 12, 256)  295168      max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 12, 12, 256)  1024        conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 12, 12, 256)  0           batch_normalization_18[0][0]     \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 12, 12, 256)  590080      activation_18[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 12, 12, 256)  1024        conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 12, 12, 256)  0           batch_normalization_19[0][0]     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 12, 12, 256)  590080      activation_19[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_20 (BatchNo (None, 12, 12, 256)  1024        conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nseparable_conv2d (SeparableConv (None, 24, 24, 64)   4736        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 12, 12, 256)  33024       max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 12, 12, 256)  0           batch_normalization_20[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 24, 24, 64)   256         separable_conv2d[0][0]           \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 12, 12, 256)  0           conv2d_17[0][0]                  \n                                                                 activation_20[0][0]              \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 24, 24, 64)   0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 12, 12, 256)  590080      add_5[0][0]                      \n__________________________________________________________________________________________________\nseparable_conv2d_1 (SeparableCo (None, 24, 24, 64)   4736        activation_6[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_21 (BatchNo (None, 12, 12, 256)  1024        conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 24, 24, 64)   256         separable_conv2d_1[0][0]         \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 12, 12, 256)  0           batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 24, 24, 64)   0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 12, 12, 256)  590080      activation_21[0][0]              \n__________________________________________________________________________________________________\nseparable_conv2d_2 (SeparableCo (None, 24, 24, 64)   4736        activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_22 (BatchNo (None, 12, 12, 256)  1024        conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 24, 24, 64)   256         separable_conv2d_2[0][0]         \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 12, 12, 256)  0           batch_normalization_22[0][0]     \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 24, 24, 64)   0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 12, 12, 256)  590080      activation_22[0][0]              \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 24, 24, 64)   0           activation_8[0][0]               \n                                                                 max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_23 (BatchNo (None, 12, 12, 256)  1024        conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 64)   0           add_1[0][0]                      \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 12, 12, 256)  0           batch_normalization_23[0][0]     \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 12, 12, 192)  0           max_pooling2d_3[0][0]            \n                                                                 max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 12, 12, 256)  0           add_5[0][0]                      \n                                                                 activation_23[0][0]              \n__________________________________________________________________________________________________\nseparable_conv2d_3 (SeparableCo (None, 12, 12, 128)  26432       concatenate[0][0]                \n__________________________________________________________________________________________________\nmax_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 256)    0           add_6[0][0]                      \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 12, 12, 128)  512         separable_conv2d_3[0][0]         \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 6, 6, 512)    1180160     max_pooling2d_5[0][0]            \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 12, 12, 128)  0           batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 6, 6, 512)    2048        conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nseparable_conv2d_4 (SeparableCo (None, 12, 12, 128)  17664       activation_15[0][0]              \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 6, 6, 512)    0           batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 12, 12, 128)  512         separable_conv2d_4[0][0]         \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 6, 6, 512)    2359808     activation_27[0][0]              \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 12, 12, 128)  0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 6, 6, 512)    2048        conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nseparable_conv2d_5 (SeparableCo (None, 12, 12, 128)  17664       activation_16[0][0]              \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 6, 6, 512)    0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 12, 12, 128)  512         separable_conv2d_5[0][0]         \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 6, 6, 512)    2359808     activation_28[0][0]              \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 12, 12, 128)  0           batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 6, 6, 512)    2048        conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 12, 12, 128)  0           activation_17[0][0]              \n                                                                 max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 6, 6, 512)    131584      max_pooling2d_5[0][0]            \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 6, 6, 512)    0           batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           add_4[0][0]                      \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 6, 6, 512)    0           conv2d_24[0][0]                  \n                                                                 activation_29[0][0]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 6, 6, 384)    0           max_pooling2d_5[0][0]            \n                                                                 max_pooling2d_4[0][0]            \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 6, 6, 512)    2359808     add_8[0][0]                      \n__________________________________________________________________________________________________\nseparable_conv2d_6 (SeparableCo (None, 6, 6, 256)    102016      concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 6, 6, 512)    2048        conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 6, 6, 256)    1024        separable_conv2d_6[0][0]         \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 6, 6, 512)    0           batch_normalization_30[0][0]     \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 6, 6, 256)    0           batch_normalization_24[0][0]     \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 6, 6, 512)    2359808     activation_30[0][0]              \n__________________________________________________________________________________________________\nseparable_conv2d_7 (SeparableCo (None, 6, 6, 256)    68096       activation_24[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 6, 6, 512)    2048        conv2d_26[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 6, 6, 256)    1024        separable_conv2d_7[0][0]         \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 6, 6, 512)    0           batch_normalization_31[0][0]     \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 6, 6, 256)    0           batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 6, 6, 512)    2359808     activation_31[0][0]              \n__________________________________________________________________________________________________\nseparable_conv2d_8 (SeparableCo (None, 6, 6, 256)    68096       activation_25[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_32 (BatchNo (None, 6, 6, 512)    2048        conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 6, 6, 256)    1024        separable_conv2d_8[0][0]         \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 6, 6, 512)    0           batch_normalization_32[0][0]     \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 6, 6, 256)    0           batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 6, 6, 512)    0           add_8[0][0]                      \n                                                                 activation_32[0][0]              \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 6, 6, 256)    0           activation_26[0][0]              \n                                                                 max_pooling2d_5[0][0]            \n__________________________________________________________________________________________________\nmax_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 512)    0           add_9[0][0]                      \n__________________________________________________________________________________________________\nmax_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 256)    0           add_7[0][0]                      \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 3, 3, 768)    0           max_pooling2d_7[0][0]            \n                                                                 max_pooling2d_6[0][0]            \n__________________________________________________________________________________________________\nseparable_conv2d_9 (SeparableCo (None, 3, 3, 512)    400640      concatenate_2[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_33 (BatchNo (None, 3, 3, 512)    2048        separable_conv2d_9[0][0]         \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 3, 3, 512)    0           batch_normalization_33[0][0]     \n__________________________________________________________________________________________________\nseparable_conv2d_10 (SeparableC (None, 3, 3, 512)    267264      activation_33[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_34 (BatchNo (None, 3, 3, 512)    2048        separable_conv2d_10[0][0]        \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 3, 3, 512)    0           batch_normalization_34[0][0]     \n__________________________________________________________________________________________________\nseparable_conv2d_11 (SeparableC (None, 3, 3, 512)    267264      activation_34[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_35 (BatchNo (None, 3, 3, 512)    2048        separable_conv2d_11[0][0]        \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 3, 3, 512)    0           batch_normalization_35[0][0]     \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 3, 3, 512)    0           activation_35[0][0]              \n                                                                 max_pooling2d_7[0][0]            \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 512)          0           add_10[0][0]                     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 64)           32832       global_average_pooling2d[0][0]   \n__________________________________________________________________________________________________\nbatch_normalization_36 (BatchNo (None, 64)           256         dense[0][0]                      \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 64)           0           batch_normalization_36[0][0]     \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 64)           0           activation_36[0][0]              \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            65          dropout[0][0]                    \n==================================================================================================\nTotal params: 18,640,001\nTrainable params: 18,622,785\nNon-trainable params: 17,216\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"## Primera ronda\n\nbatch_size = 128 # Tamaño de los lotes (grupos de imágenes)\nh5_path = \"./model_2.h5\"\n\n# ModelCheckpoint (función callback) se usa con las funciones de entrenamiento de modelo (model.fit o\n# model.fit_generator) para grabar los pesos (weights, que junto con los biases son los parámetros que aprende el\n# modelo) generados por el entrenamiento, en un archivo, cada cierto intervalo, de modo que el modelo o los pesos\n# (weights) pueden ser leídos en otro momento para continuar el entrenamiento desde ese punto de avance.\ncheckpoint = ModelCheckpoint(h5_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\n# Se realiza el entrenamiento en sí. Se usa fit_generator (y no fit) cuando el dataset es muy grande y no entra\n# en memoria. El método retorna algunos valores del entrenamiento.\n# https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/\nhistory = model.fit_generator(\n    data_gen(train, id_label_map, batch_size, augment = True), # Materia prima para entrenar: imágenes.\n    validation_data = data_gen(val, id_label_map, batch_size), # Las imágenes para validar\n    epochs = 15, # Cuántas pasadas hará el modelo por cada set de datos\n    verbose = 1, # Qué se mostrará mientras se entrena: 1 = barra de progreso\n    callbacks = [checkpoint], # Ya explicado arriba\n    steps_per_epoch = len(train), # Tamaño de los lotes de entrenamiento,\n    validation_steps = len(val)) # Tamaño de los lotes de validación)\n\n# Los pesos (weights) y los biases (sesgos) son los parámetros que \"aprende\" el modelo luego de entrenar, con los\n# que luego puede hacer predicciones. Aquí se graban los pesos, para todas las capas del modelo. De esta forma se\n# puede suspender la ejecución al final de este bloque código y en otro momento cargarlos y retomar la ejección\n# del siguiente bloque.\n# https://keras.io/api/models/model_saving_apis/#saveweights-method\nmodel.save_weights(h5_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Se verifica que se haya grabado el archivo, listando el contenido de la carpeta.\nos.listdir('../input/')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Segunda ronda\n\nh5_path = \"./model_2.h5\"\nmodel.load_weights(h5_path)\nbatch_size = 128\ncheckpoint = ModelCheckpoint(h5_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nhistory = model.fit_generator(\n    data_gen(train, id_label_map, batch_size, augment=True),\n    validation_data=data_gen(val, id_label_map, batch_size),\n    epochs=15, verbose=1,\n    callbacks = [checkpoint],\n    steps_per_epoch = len(train),\n    validation_steps = len(val))\n\nmodel.save_weights(h5_path)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T21:40:56.155385Z","iopub.execute_input":"2022-11-18T21:40:56.156577Z","iopub.status.idle":"2022-11-18T21:40:56.223250Z","shell.execute_reply.started":"2022-11-18T21:40:56.156538Z","shell.execute_reply":"2022-11-18T21:40:56.222116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tercera ronda\n\nh5_path = \"./model_2.h5\"\nmodel.load_weights(h5_path)\nbatch_size = 128\ncheckpoint = ModelCheckpoint(h5_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nhistory = model. (\n    data_gen(train, id_label_map, batch_size, augment=True),\n    validation_data = data_gen(val, id_label_map, batch_size),\n    epochs = 5, verbose = 1,\n    callbacks = [checkpoint],\n    steps_per_epoch = len(train),\n    validation_steps = len(val))\n\nmodel.save_weights(h5_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# Se muestran 2 gráficos de resultados de entrenamiento y validación.\n# El primer parámetro son las coordenadas en X, el segundo las coordenadas en Y, \n# el tercero el tipo de formato, como color, si son puntos o líneas... (b = blue, o = circulitos), se trazan dos\n# secuencias por gráfico, uno con líneas otro con puntos (círculos).\n# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\nplt.plot(epochs, acc, 'bo', label='Train acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\n\n# Prepara la leyenda, que es el cartel dentro del gráfico que dice a qué corresponde cada secuencia (una línea,\n# o secuencia de puntos)\n# https://matplotlib.org/stable/api/legend_api.html\nplt.legend()\n\n# Comienza otro gráfico.\n# https://matplotlib.org/stable/api/figure_api.html\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Train loss')\nplt.plot(epochs, val_loss,'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\n# Muestra los gráficos que se prepararon.\n# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.show.html\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = [] # Vector donde se guardarán todas las predicciones\nids = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A predecir, amigos!\n\nmodel.load_weights(h5_path) # Se cargan los parámetros ya entrenados\n\n# Se divide el dataset de test en lotes, y por cada uno...\nfor batch in chunker(test_files, batch_size):\n    # Preprocesamiento de las imágenes, leyéndolas primero de disco, ya que 'test_files' contiene solo nombres\n    # de archivo.\n    X = [preprocess_input(cv2.imread(x)) for x in batch]\n    \n    # Obtiene los IDs alfanuméricos, a partir de los nombres de archivos\n    ids_batch = [get_id_from_file_path(x) for x in batch]\n    \n    # Se convierte el lote a un array de la librería NumPy (NUMerical PYthon)\n    X = np.array(X)\n    \n    # Aquí se almacenarán las predicciones para este lote\n    preds_batch = (\n                    (\n                        # model.predict, imposible no intuirlo por el nombre, realiza las predicciones de lo\n                        # que se le envía en X.\n                        # ravel() cambia la forma de la matriz por un vector en 1 dimensión.\n                        # https://keras.io/api/models/model_training_apis/\n                        # ::-1 se relaciona con start:stop:step, y en este caso implica cambiar el sentido de\n                        # recorrido por el inverso.\n                        # ¿Por qué se predice 4 veces, mandándole esos [:, ::-1, :, :] raros?\n                        # Primero predice las imágenes tal como están, luego las predice invirtiendo el orden\n                        # de las filas (como poniéndoles un espejo encima), luego las predice invirtiendo el\n                        # orden de las filas y de las columnas, y por último solo invirtiendo el orden de las\n                        # columnas (el orden de los colores, 4ta dimensión, nunca se invierte).\n                        model.predict(X).ravel() * model.predict(X[:, ::-1, :, :]).ravel()\n                        * model.predict(X[:, ::-1, ::-1, :]).ravel()\n                        * model.predict(X[:, :, ::-1, :]).ravel() \n                    ) \n        \n                    # El doble asterisco es para calcular potencias. Lo eleva a 1/4 para compensar que\n                    # previamente se multiplicaron 4 predicciones entre si.\n                    ** 0.25         \n    \n                # Convierte el array a una lista ordinaria\n                # https://www.educative.io/answers/what-is-the-array-tolist-function-in-python\n                ).tolist() \n    \n    \n    preds += preds_batch # Incorpora las predicciones de este lote al listado final.\n    ids += ids_batch # Incorpora los ids de este lote al listado final","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Se genera un dataframe con los ids y las predicciones\ndf = pd.DataFrame({'id':ids, 'label':preds})\n\n# Se guarda en archivo CSV, que es el que se presentó a la competencia\ndf.to_csv(\"baseline_nasnet.csv\", index=False)\n\n# Se muestran las 5 primeras líneas del resultado\ndf.head()","metadata":{},"execution_count":null,"outputs":[]}]}